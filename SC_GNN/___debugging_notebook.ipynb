{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd02460",
   "metadata": {},
   "source": [
    "### Modular python script of SR-GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c0f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : fgenv\n",
      "    active env location : C:\\Users\\Sikdara\\.conda\\envs\\fgenv\n",
      "            shell level : 2\n",
      "       user config file : C:\\Users\\Sikdara\\.condarc\n",
      " populated config files : C:\\Users\\Sikdara\\.condarc\n",
      "          conda version : 22.9.0\n",
      "    conda-build version : 3.22.0\n",
      "         python version : 3.9.13.final.0\n",
      "       virtual packages : __cuda=11.7=0\n",
      "                          __win=0=0\n",
      "                          __archspec=1=x86_64\n",
      "       base environment : C:\\ProgramData\\Anaconda3  (read only)\n",
      "      conda av data dir : C:\\ProgramData\\Anaconda3\\etc\\conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\ProgramData\\Anaconda3\\pkgs\n",
      "                          C:\\Users\\Sikdara\\.conda\\pkgs\n",
      "                          C:\\Users\\Sikdara\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\Users\\Sikdara\\.conda\\envs\n",
      "                          C:\\ProgramData\\Anaconda3\\envs\n",
      "                          C:\\Users\\Sikdara\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/22.9.0 requests/2.28.1 CPython/3.9.13 Windows/10 Windows/10.0.19045\n",
      "          administrator : False\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c497fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available -->  1\n",
      " \n",
      "tensorflow version --> 2.10.0\n",
      " \n",
      "python version --> 3.9.16\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from platform import python_version\n",
    "\n",
    "print(\"Num GPUs Available --> \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\" \")\n",
    "print('tensorflow version -->',tf.__version__)\n",
    "print(\" \")\n",
    "print('python version -->', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cf1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5360c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(\u001b[38;5;18;43m__file__\u001b[39;49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.path.realpath(__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce3ba5",
   "metadata": {},
   "source": [
    "### Importing data parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b00e377d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATA': {'nb_classes': 100,\n",
       "  'image_size': [224, 224],\n",
       "  'dataset_dir': '/mnt/DataStore/projects_share/datasets/Aircraft'},\n",
       " 'HARDWARE': {'multi_gpu': False, 'gpu_id': -1, 'gpu_utilisation': 1},\n",
       " 'AUGMENTATION': {'aug_zoom': 0.15,\n",
       "  'aug_tx': 0,\n",
       "  'aug_ty': 0,\n",
       "  'aug_rotation': 15},\n",
       " 'MODEL': {'batch_size': 16, 'learning_rate': 0.01, 'model_name': 'model'},\n",
       " 'TRAIN': {'validation_freq': 5,\n",
       "  'checkpoint_freq': 50,\n",
       "  'epochs': 200,\n",
       "  'alpha_teleport': 0.4,\n",
       "  'channels': '512_test',\n",
       "  'learning_rate': 0.01}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml, json\n",
    "\n",
    "with open('config.yaml', 'r') as file:\n",
    "    param = yaml.load(file, Loader=yaml.FullLoader)\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1af9eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter configuration: \n",
      " {\n",
      "   \"AUGMENTATION\": {\n",
      "      \"aug_rotation\": 15,\n",
      "      \"aug_tx\": 0,\n",
      "      \"aug_ty\": 0,\n",
      "      \"aug_zoom\": 0.15\n",
      "   },\n",
      "   \"DATA\": {\n",
      "      \"dataset_dir\": \"/mnt/DataStore/projects_share/datasets/Aircraft\",\n",
      "      \"image_size\": [\n",
      "         224,\n",
      "         224\n",
      "      ],\n",
      "      \"nb_classes\": 100\n",
      "   },\n",
      "   \"HARDWARE\": {\n",
      "      \"gpu_id\": -1,\n",
      "      \"gpu_utilisation\": 1,\n",
      "      \"multi_gpu\": false\n",
      "   },\n",
      "   \"MODEL\": {\n",
      "      \"batch_size\": 16,\n",
      "      \"learning_rate\": 0.01,\n",
      "      \"model_name\": \"model\"\n",
      "   },\n",
      "   \"TRAIN\": {\n",
      "      \"alpha_teleport\": 0.4,\n",
      "      \"channels\": \"512_test\",\n",
      "      \"checkpoint_freq\": 50,\n",
      "      \"epochs\": 200,\n",
      "      \"learning_rate\": 0.01,\n",
      "      \"validation_freq\": 5\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " print('parameter configuration: \\n', json.dumps(param, sort_keys = True, indent = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c10eba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# << data parameters >>\n",
    "nb_classes = param['DATA']['nb_classes']\n",
    "image_size = tuple( param['DATA']['image_size'] )\n",
    "dataset_dir = param['DATA']['dataset_dir']\n",
    "\n",
    "# << hardware parameters >>   ~~~~~~~~~~~~~~~~~~~\n",
    "multi_gpu = param['HARDWARE']['multi_gpu']\n",
    "gpu_id = param['HARDWARE']['gpu_id']\n",
    "gpu_utilisation = param['HARDWARE']['gpu_utilisation']\n",
    "\n",
    "# << augmentation parameters >>\n",
    "aug_zoom = param['AUGMENTATION']['aug_zoom']\n",
    "aug_tx = param['AUGMENTATION']['aug_tx']\n",
    "aug_ty = param['AUGMENTATION']['aug_ty']\n",
    "aug_rotation= param['AUGMENTATION']['aug_rotation']\n",
    "\n",
    "# << model parameters >>    ~~~~~~~~~~~~~~~~~~~\n",
    "batch_size =  param['MODEL']['batch_size']\n",
    "lr = param['MODEL']['learning_rate']\n",
    "model_name = param['MODEL']['model_name']\n",
    "\n",
    "# << training parameters >>\n",
    "validation_freq = param['TRAIN']['validation_freq']\n",
    "checkpoint_freq = param['TRAIN']['checkpoint_freq']\n",
    "epochs = param['TRAIN']['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7bdd5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_classes -->  100 <class 'int'>\n",
      "image_size -->  (224, 224) <class 'tuple'>\n",
      "dataset_dir -->  /mnt/DataStore/projects_share/datasets/Aircraft <class 'str'>\n",
      " \n",
      "multi_gpu -->  False <class 'bool'>\n",
      "gpu_id -->  -1 <class 'int'>\n",
      "gpu_utilisation -->  1 <class 'int'>\n",
      " \n",
      "aug_zoom -->  0.15 <class 'float'>\n",
      "aug_ty -->  0 <class 'int'>\n",
      " \n",
      "batch_size -->  16 <class 'int'>\n",
      "learning_rate -->  0.01 <class 'float'>\n",
      " \n",
      "validation_freq -->  5 <class 'int'>\n",
      "checkpoint_freq -->  50 <class 'int'>\n",
      "epochs -->  200 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print('nb_classes --> ', nb_classes, type(nb_classes))\n",
    "print('image_size --> ', image_size, type(image_size))\n",
    "print('dataset_dir --> ', dataset_dir, type(dataset_dir))\n",
    "print(' ')\n",
    "print('multi_gpu --> ', multi_gpu, type(multi_gpu))\n",
    "print('gpu_id --> ', gpu_id, type(gpu_id))\n",
    "print('gpu_utilisation --> ', gpu_utilisation, type(gpu_utilisation))\n",
    "print(' ')\n",
    "print('aug_zoom --> ', aug_zoom, type(aug_zoom))\n",
    "print('aug_ty --> ', aug_ty, type(aug_ty))\n",
    "print(' ')\n",
    "print('batch_size --> ', batch_size, type(batch_size))\n",
    "print('learning_rate --> ', lr, type(lr))\n",
    "# print('optimizer --> ', optimizer, type(optimizer))\n",
    "# print('model --> ', model, type(model))\n",
    "print(' ')\n",
    "print('validation_freq --> ', validation_freq, type(validation_freq))\n",
    "print('checkpoint_freq --> ', checkpoint_freq, type(checkpoint_freq))\n",
    "print('epochs --> ', epochs, type(epochs))\n",
    "# print('alpha_teleport --> ', alpha_teleport, type(alpha_teleport))\n",
    "# print('channels --> ', channels, type(channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f04e7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/sikdara/anaconda3/envs/fgenv/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Fri Jun 16 09:58:52 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   56C    P0    68W / 250W |  14962MiB / 46080MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     Off  | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   22C    P8    13W / 250W |      8MiB / 46080MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1347701      C   python                           4946MiB |\n",
      "|    0   N/A  N/A   1348285      C   python                           5058MiB |\n",
      "|    0   N/A  N/A   1348728      C   python                           4950MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c578ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec7b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17acb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# =============== load and compile ~DEFAULT CONFIGURATION~ parameters\n",
    "param_dir = \"parameters.txt\"\n",
    "with  open(param_dir, \"r\") as paramf:\n",
    "    params = paramf.readlines()\n",
    "\n",
    "# << data parameters >>\n",
    "nb_classes = int(params[1].split(\":\")[-1].rstrip())\n",
    "image_size = ast.literal_eval(params[2].split(\":\")[-1].rstrip())\n",
    "dataset_dir = params[3].split(\":\")[-1].rstrip()\n",
    "\n",
    "# << hardware parameters >>   ~~~~~~~~~~~~~~~~~~~\n",
    "multi_gpu = ast.literal_eval(params[6].split(\":\")[-1].rstrip())\n",
    "gpu_id = params[7].split(\":\")[-1].rstrip()\n",
    "gpu_utilisation = float(params[8].split(\":\")[-1].rstrip())\n",
    "\n",
    "# << augmentation parameters >>\n",
    "aug_zoom = float(params[11].split(\":\")[-1].rstrip())\n",
    "aug_tx = int(params[12].split(\":\")[-1].rstrip())\n",
    "aug_ty = int(params[13].split(\":\")[-1].rstrip())\n",
    "aug_rotation= int(params[14].split(\":\")[-1].rstrip())\n",
    "\n",
    "# << model parameters >>    ~~~~~~~~~~~~~~~~~~~\n",
    "batch_size = int(params[17].split(\":\")[-1].rstrip())\n",
    "lr = float(params[18].split(\":\")[-1].rstrip())\n",
    "#optimizer = eval(params[19].split(\":\")[-1].rstrip())\n",
    "model_name = params[20].split(\":\")[-1].rstrip()\n",
    "\n",
    "# << training parameters >>\n",
    "validation_freq = int(params[23].split(\":\")[-1].rstrip())\n",
    "checkpoint_freq = int(params[24].split(\":\")[-1].rstrip())\n",
    "epochs = int(params[25].split(\":\")[-1].rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952bbd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_classes -->  100 <class 'int'>\n",
      "image_size -->  (224, 224) <class 'tuple'>\n",
      "dataset_dir -->  /mnt/DataStore/projects_share/datasets/Aircraft <class 'str'>\n",
      " \n",
      "multi_gpu -->  False <class 'bool'>\n",
      "gpu_id -->   -1 <class 'str'>\n",
      "gpu_utilisation -->  1.0 <class 'float'>\n",
      " \n",
      "aug_zoom -->  0.15 <class 'float'>\n",
      "aug_ty -->  0 <class 'int'>\n",
      " \n",
      "batch_size -->  16 <class 'int'>\n",
      "learning_rate -->  0.01 <class 'float'>\n",
      " \n",
      "validation_freq -->  5 <class 'int'>\n",
      "checkpoint_freq -->  50 <class 'int'>\n",
      "epochs -->  200 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print('nb_classes --> ', nb_classes, type(nb_classes))\n",
    "print('image_size --> ', image_size, type(image_size))\n",
    "print('dataset_dir --> ', dataset_dir, type(dataset_dir))\n",
    "print(' ')\n",
    "print('multi_gpu --> ', multi_gpu, type(multi_gpu))\n",
    "print('gpu_id --> ', gpu_id, type(gpu_id))\n",
    "print('gpu_utilisation --> ', gpu_utilisation, type(gpu_utilisation))\n",
    "print(' ')\n",
    "print('aug_zoom --> ', aug_zoom, type(aug_zoom))\n",
    "print('aug_ty --> ', aug_ty, type(aug_ty))\n",
    "print(' ')\n",
    "print('batch_size --> ', batch_size, type(batch_size))\n",
    "print('learning_rate --> ', lr, type(lr))\n",
    "# print('optimizer --> ', optimizer, type(optimizer))\n",
    "# print('model --> ', model, type(model))\n",
    "print(' ')\n",
    "print('validation_freq --> ', validation_freq, type(validation_freq))\n",
    "print('checkpoint_freq --> ', checkpoint_freq, type(checkpoint_freq))\n",
    "print('epochs --> ', epochs, type(epochs))\n",
    "# print('alpha_teleport --> ', alpha_teleport, type(alpha_teleport))\n",
    "# print('channels --> ', channels, type(channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f282a977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#~~~~~~~~~~~~~~~~~~~     data parameters     ~~~~~~~~~~~~~~~~~~~\\n',\n",
       " 'nb_classes:100\\n',\n",
       " 'image_size:(224,224)\\n',\n",
       " 'dataset_dir:/mnt/DataStore/projects_share/datasets/Aircraft\\n',\n",
       " '\\n',\n",
       " '#~~~~~~~~~~~~~~~~~~~   hardware parameters   ~~~~~~~~~~~~~~~~~~~\\n',\n",
       " 'multi_gpu:False\\n',\n",
       " 'gpu_id: -1\\n',\n",
       " 'gpu_utilisation:1\\n',\n",
       " '\\n',\n",
       " '#~~~~~~~~~~~~~~~~~~~ augmentation parameters ~~~~~~~~~~~~~~~~~~~\\n',\n",
       " 'aug_zoom:0.15\\n',\n",
       " 'aug_tx:0\\n',\n",
       " 'aug_ty:0\\n',\n",
       " 'aug_rotation:15\\n',\n",
       " '\\n',\n",
       " '#~~~~~~~~~~~~~~~~~~~    model parameters     ~~~~~~~~~~~~~~~~~~~\\n',\n",
       " 'batch_size:16\\n',\n",
       " 'learning_rate:0.01\\n',\n",
       " 'optimizer:SGD(lr=0.01)\\n',\n",
       " 'model_name:model\\n',\n",
       " '\\n',\n",
       " '#~~~~~~~~~~~~~~~~~~~   training parameters   ~~~~~~~~~~~~~~~~~~~\\n',\n",
       " 'validation_freq:5\\n',\n",
       " 'checkpoint_freq:50\\n',\n",
       " 'epochs:200\\n',\n",
       " 'alpha_teleport:0.40 \\n',\n",
       " 'channels:512_test\\n',\n",
       " 'learning_rate:0.01']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0406706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4e007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bf2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0dd787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: (?, 42, 42, 2048)\n",
      "Original tensor shape: (?, 2048, 1764)\n",
      "Restored tensor shape: (?, 42, 42, 2048)\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Create a tensor\n",
    "tensor = tf.placeholder(tf.float32, shape=(None, 42, 42, 2048))\n",
    "\n",
    "# Convert to (None, 2048, 1764)\n",
    "transposed_tensor = tf.transpose(tensor, perm=[0, 3, 1, 2])\n",
    "reshaped_tensor = tf.reshape(transposed_tensor, shape=(-1, 2048, 1764))\n",
    "\n",
    "# Convert back to (None, 42, 42, 2048)\n",
    "restored_tensor = tf.transpose(reshaped_tensor, perm=[0, 2, 1])\n",
    "reshaped_back_tensor = tf.reshape(restored_tensor, shape=(-1, 42, 42, 2048))\n",
    "\n",
    "# Print the shapes of original and restored tensors\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "print(\"Original tensor shape:\", reshaped_tensor.shape)\n",
    "print(\"Restored tensor shape:\", reshaped_back_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48a42fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 * 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "47bd0a29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic tf.Tensor (split_9:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\fgenv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2007\u001b[0m, in \u001b[0;36mshape\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   2006\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2007\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# print(expanded_tensor.shape)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Split the tensor along the channel dimension (axis=3)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m splits \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msplit(tensor, num_or_size_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# The result is a list of tensors\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Each tensor has shape [batch_size, height, width, split_channels]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m sp_all \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\fgenv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009\u001b[0m, in \u001b[0;36mshape\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   2007\u001b[0m     result \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m-> 2009\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   2010\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\fgenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:924\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m dtype\n\u001b[1;32m--> 924\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    925\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert a symbolic tf.Tensor (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) to a numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    926\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This error may indicate that you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to pass a Tensor to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    927\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a NumPy call, which is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic tf.Tensor (split_9:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Assume you have a tensor with shape [batch_size, height, width, channels]\n",
    "tensor = tf.random.normal([4, 2048, 42, 42])\n",
    "\n",
    "expanded_tensor = tf.expand_dims(tensor, axis = 1)\n",
    "# print(expanded_tensor.shape)\n",
    "\n",
    "# Split the tensor along the channel dimension (axis=3)\n",
    "splits = tf.split(tensor, num_or_size_splits=4, axis=1)\n",
    "print(np.shape(splits))\n",
    "\n",
    "# The result is a list of tensors\n",
    "# Each tensor has shape [batch_size, height, width, split_channels]\n",
    "sp_all = []\n",
    "for split in splits:\n",
    "    print('-----------')\n",
    "    print(split.shape)\n",
    "    a = tf.reshape(split, shape=(-1, 4, (2048//4) * 42 * 42  ))\n",
    "    sp_all.append(a)\n",
    "    print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73dc1237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 4, 903168)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sp_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20e3b897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 903168])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.reshape(expanded_tensor, shape = (-1, 4, (2048//4) * 42 * 42))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bff61b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(903168,), dtype=float32, numpy=\n",
       "array([-2.25943   ,  1.6523793 , -0.99794465, ...,  1.4130237 ,\n",
       "       -1.2022934 ,  1.014423  ], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23387b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03214f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e761e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(903168,), dtype=float32, numpy=\n",
       "array([-1.9232527 , -0.47618198, -1.4552858 , ...,  1.3851614 ,\n",
       "       -0.26174375,  0.7149143 ], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_all[0][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0b5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5bc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f136de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2cc4ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened split 1 shape: (4, 4096)\n",
      "Flattened split 2 shape: (4, 4096)\n",
      "Flattened split 3 shape: (4, 4096)\n",
      "Flattened split 4 shape: (4, 4096)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a tensor with shape [batch_size, channels, height, width]\n",
    "tensor = tf.random.normal([4, 16, 32, 32])\n",
    "\n",
    "# Split the tensor into four parts along the channel dimension (axis=1)\n",
    "splits = tf.split(tensor, num_or_size_splits=4, axis=1)\n",
    "\n",
    "# Flatten each split\n",
    "flattened_splits = [tf.reshape(split, [split.shape[0], -1]) for split in splits]\n",
    "\n",
    "for i, split in enumerate(flattened_splits):\n",
    "    print(\"Flattened split\", i+1, \"shape:\", split.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "430f6094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 4, 32, 32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ffca4183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose_7:0\", shape=(4, 2048, 42, 42), dtype=float32)\n",
      " \n",
      "[<tf.Tensor 'split_57:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'split_57:1' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'split_57:2' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'split_57:3' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'split_57:4' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'split_57:5' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'split_57:6' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'split_57:7' shape=(4, 256, 42, 42) dtype=float32>] 8\n",
      " \n",
      "[<tf.Tensor 'ExpandDims_189:0' shape=(4, 1, 451584) dtype=float32>, <tf.Tensor 'ExpandDims_190:0' shape=(4, 1, 451584) dtype=float32>, <tf.Tensor 'ExpandDims_191:0' shape=(4, 1, 451584) dtype=float32>, <tf.Tensor 'ExpandDims_192:0' shape=(4, 1, 451584) dtype=float32>, <tf.Tensor 'ExpandDims_193:0' shape=(4, 1, 451584) dtype=float32>, <tf.Tensor 'ExpandDims_194:0' shape=(4, 1, 451584) dtype=float32>, <tf.Tensor 'ExpandDims_195:0' shape=(4, 1, 451584) dtype=float32>, <tf.Tensor 'ExpandDims_196:0' shape=(4, 1, 451584) dtype=float32>] 8\n",
      " \n",
      "Tensor(\"concat_43:0\", shape=(4, 8, 451584), dtype=float32)\n",
      " \n",
      "[<tf.Tensor 'Reshape_342:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'Reshape_343:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'Reshape_344:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'Reshape_345:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'Reshape_346:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'Reshape_347:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'Reshape_348:0' shape=(4, 256, 42, 42) dtype=float32>, <tf.Tensor 'Reshape_349:0' shape=(4, 256, 42, 42) dtype=float32>] 8\n",
      " \n",
      "(4, 2048, 42, 42)\n",
      "Tensor(\"transpose_8:0\", shape=(4, 42, 42, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cnodes = 8\n",
    "base_dims = 2048\n",
    "\n",
    "\n",
    "# Assume you have a tensor with shape [batch_size, channels, height, width]\n",
    "tensor = tf.random.normal([4, 42, 42, 2048])\n",
    "transposed_tensor = tf.transpose(tensor, perm=[0, 3, 1, 2])\n",
    "print(transposed_tensor)\n",
    "print(' ')\n",
    "\n",
    "\n",
    "# Split into cnodes components\n",
    "splits = tf.split(transposed_tensor, num_or_size_splits = cnodes, axis=1)\n",
    "print(splits, len(splits))\n",
    "print(' ')\n",
    "\n",
    "# Flatten each split\n",
    "flattened_splits = [tf.expand_dims( tf.reshape(split, [split.shape[0], -1]), 1 ) for split in splits]\n",
    "print(flattened_splits, len(flattened_splits))\n",
    "print(' ')\n",
    "\n",
    "# Concatenate into single tensor\n",
    "joined = tf.concat(flattened_splits, 1)\n",
    "print(joined)\n",
    "print(' ')\n",
    "\n",
    "# Apply channel wise gcn\n",
    "\n",
    "\n",
    "# Restoring back to original tensor\n",
    "restore_tensor = [tf.reshape(x, shape=(-1, base_dims//cnodes, 42, 42))   for x in tf.split(joined, num_or_size_splits = cnodes, axis=1)]\n",
    "print(restore_tensor, len(restore_tensor))\n",
    "print(' ')\n",
    "\n",
    "restore_tensor = tf.concat(restore_tensor, 1)\n",
    "print(restore_tensor.shape)\n",
    "\n",
    "# Permute back to Channel last\n",
    "restore_tensor = tf.transpose(restore_tensor, perm = [0, 2, 3, 1])\n",
    "print(restore_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2fe8a867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'split_20:0' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:1' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:2' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:3' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:4' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:5' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:6' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:7' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:8' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:9' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:10' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:11' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:12' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:13' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:14' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:15' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:16' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:17' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:18' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:19' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:20' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:21' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:22' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:23' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:24' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:25' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:26' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:27' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:28' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:29' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:30' shape=(4, 64, 42, 42) dtype=float32>,\n",
       " <tf.Tensor 'split_20:31' shape=(4, 64, 42, 42) dtype=float32>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5faa7958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'ExpandDims:0' shape=(4, 1, 903168) dtype=float32>,\n",
       " <tf.Tensor 'ExpandDims_1:0' shape=(4, 1, 903168) dtype=float32>,\n",
       " <tf.Tensor 'ExpandDims_2:0' shape=(4, 1, 903168) dtype=float32>,\n",
       " <tf.Tensor 'ExpandDims_3:0' shape=(4, 1, 903168) dtype=float32>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8fc04090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_15:0' shape=(4, 512, 42, 42) dtype=float32>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(joined[1], shape=(-1, 512, 42, 42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "face506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits2 = tf.split(joined, num_or_size_splits = cnodes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb41dfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_24:0' shape=(4, 512, 42, 42) dtype=float32>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(splits2[1], shape=(-1, 512, 42, 42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c1f206dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_9:0' shape=(4, 2048, 42, 42) dtype=float32>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0f9370df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_normal_15:0' shape=(4, 2048, 42, 42) dtype=float32>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed883635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01cd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
